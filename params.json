{"name":"Scrapebgmenen","tagline":"Scrapy pagination demo","body":"# ScrapeBGMenen\r\nScrapy pagination demo\r\n\r\n#About ScrapeBGMenen\r\nBased on Scrapy, this is a small script that gets the adresses of the companies listed on the website http://www.menen.be/bedrijvengids. The \"BG\" stands for BedrijvenGids, translated to Company Guide, a directory of all companies in the municipality of Menin (Belgium), where I live.\r\n\r\nIt is not my intention to use the resulting data, as this could infringe privacy laws, I don't know. My intention is to learn the Scrapy web scraper framework. There is no better way to learn than to do it on real data. The specific case for this was the fact that this website used pagination.\r\n\r\nI open sourced it so you could maybe learn from it, recieve feedback and demo my work.\r\n\r\nSetup\r\n=====\r\n\r\nInstall the Python package 'virtualenv':\r\n\r\n    sudo pip install virtualenv\r\n\r\nCreate a virtual environment for Python libraries:\r\n\r\n    virtualenv venv\r\n\r\nActivate the virtual environment:\r\n\r\n    source ./venv/bin/activate\r\n\r\nInstall the Python library dependencies of this repo:\r\n\r\n    pip install -r requirements.txt\r\n\r\nRun the script:\r\n\r\n    cd bgscraper\r\n    scrapy crawl bgm -o adressen.csv\r\n    \r\nLicense:\r\nGNU Affero GPLv3 or later.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}